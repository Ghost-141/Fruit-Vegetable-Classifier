{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the directory according to your choice\n",
    "Train_Dir = \"Fruit Classification/train\"\n",
    "Val_Dir = \"Fruit Classification/validation\"\n",
    "Test_Dir = \"Fruit Classification/test\"\n",
    "BATCH_SIZE = 40 #adjust it according to your GPU VRAM\n",
    "Img_Size = (192, 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callback Function to Avoid Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check the loss\n",
    "        if logs['accuracy'] > 0.90 and logs['val_accuracy'] > 0.90:\n",
    "            # Stop if threshold is met\n",
    "            print(\"\\nAccuracy has reached tp 90% so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_dataset():\n",
    "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=Train_Dir,\n",
    "        image_size=(Img_Size),\n",
    "        batch_size= BATCH_SIZE,\n",
    "        color_mode='rgb',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataset= tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=Val_Dir,\n",
    "        image_size= (Img_Size),\n",
    "        batch_size= BATCH_SIZE,\n",
    "        color_mode= 'rgb',\n",
    "    )\n",
    "\n",
    "    test_dataset= tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=Test_Dir,\n",
    "        image_size= (Img_Size),\n",
    "        batch_size= BATCH_SIZE,\n",
    "        color_mode= 'rgb',\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = train_val_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model= tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(192,192, 3)),\n",
    "        tf.keras.layers.Rescaling(1.0/255),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(36)  \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = base_model()\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = custom_model.fit(train_dataset, validation_data=val_dataset, epochs=40, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation accuracy from history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Training and validation accuracy')\n",
    "\n",
    "for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], [\"Accuracy\", \"Loss\"])):\n",
    "    ax[i].plot(epochs, data[0], 'r', label=\"Training \" + label)\n",
    "    ax[i].plot(epochs, data[1], 'b', label=\"Validation \" + label)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save(\"C:/Users/Imtiaz/Downloads/Compressed/Fruit Classification/custom_cnn_93%.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction On Any Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = tf.keras.models.load_model(\"C:/Users/Imtiaz/Downloads/Compressed/Fruit Classification/custom_cnn_93%.h5\")\n",
    "\n",
    "image = 'potato1.jpeg' # image directotry \n",
    "image = tf.keras.utils.load_img(image, target_size=(192,192))\n",
    "img_array = tf.keras.utils.img_to_array(image)\n",
    "img_batch = tf.expand_dims(img_array, 0)\n",
    "prediction = model.predict(img_batch)\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "score = tf.nn.softmax(prediction[0])\n",
    "predicted_class = class_names[np.argmax(score)]\n",
    "accuracy = np.max(score) * 100\n",
    "\n",
    "# Plot the image with actual and predicted labels\n",
    "actual_label = \"Potato\" \n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Actual: {actual_label}\\nPredicted: {predicted_class} ({accuracy:.2f}%)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-Interface Interface With Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import gradio as gr\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model(\"C:/Users/Imtiaz/Downloads/Compressed/Fruit Classification/custom_cnn_93%.h5\")\n",
    "\n",
    "# Class Names\n",
    "class_map = [\n",
    "    'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower',\n",
    "    'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi',\n",
    "    'lemon', 'lettuce', 'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple',\n",
    "    'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato',\n",
    "    'turnip', 'watermelon']\n",
    "\n",
    "def prediction(test_image):\n",
    "    \"\"\"Make a prediction using the loaded model and show the result.\"\"\"\n",
    " \n",
    "    # Load and prepare the image\n",
    "    test_img = image.load_img(test_image, target_size=(192, 192)) \n",
    "    test_img_array = image.img_to_array(test_img)\n",
    "    test_img_batch = tf.expand_dims(test_img_array, 0)\n",
    "\n",
    "    # Make Prediction \n",
    "    prediction = model.predict(test_img_batch)\n",
    "    score = tf.nn.softmax(prediction[0])\n",
    "    predicted_class = class_map[np.argmax(score)]\n",
    "    confidence = np.max(score)*100\n",
    "    return f\"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%\"\n",
    "\n",
    "sample_images= ['Apple.jpg','corn.jpg','potato1.jpeg','Tomato.jpg','Banana.jpg']\n",
    "\n",
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=prediction, \n",
    "    inputs=gr.Image(type=\"filepath\"),\n",
    "    outputs=\"text\", \n",
    "    title=\"Vegetable & Fruit Classifer\",\n",
    "    examples=sample_images,\n",
    "    description=\"Upload image of any vegetable or furit to classify.\\n\\n ![Vegetable GIF](https://media.giphy.com/media/LrY6OiICHS1TWZpGkf/giphy.gif)\"\n",
    ")\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
